{
    "performance_summary": {
        "Throughput": 398.329,
        "Latency": [
            2.35828,
            3.11499,
            2.50909,
            2.4751,
            2.53552,
            2.74126,
            2.92456
        ],
        "Enqueue Time": [
            0.000976562,
            0.00354004,
            0.00143721,
            0.00146484,
            0.00170898,
            0.00183105,
            0.00219727
        ],
        "H2D Latency": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        "GPU Compute Time": [
            2.35828,
            3.11499,
            2.50909,
            2.4751,
            2.53552,
            2.74126,
            2.92456
        ],
        "D2H Latency": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        "Total Host Walltime": 3.00255,
        "Total GPU Compute Time": 3.00088
    },
    "inference_options": {
        "Batch": "1",
        "Input inference shapes": "model",
        "Iterations": "10",
        "Duration": "3s (+ 200ms warm up)",
        "Sleep time": "0ms",
        "Idle time": "0ms",
        "Inference Streams": "1",
        "ExposeDMA": "Disabled",
        "Data transfers": "Disabled",
        "Spin-wait": "Enabled",
        "Multithreading": "Disabled",
        "CUDA Graph": "Enabled",
        "Separate profiling": "Enabled",
        "Time Deserialize": "Disabled",
        "Time Refit": "Disabled",
        "NVTX verbosity": "2",
        "Persistent Cache Ratio": "0",
        "Inputs": ""
    },
    "device_information": {
        "Selected Device": "NVIDIA GeForce RTX 4080 Laptop GPU",
        "Compute Capability": 8.9,
        "SMs": 58.0,
        "Device Global Memory": "11980 MiB",
        "Shared Memory per SM": "100 KiB",
        "Memory Bus Width": 192.0,
        "Application Compute Clock Rate": "2.28 GHz",
        "Application Memory Clock Rate": "9.001 GHz"
    }
}